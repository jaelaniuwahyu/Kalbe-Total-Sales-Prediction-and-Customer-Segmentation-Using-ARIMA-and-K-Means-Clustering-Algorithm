# -*- coding: utf-8 -*-
"""Kalbe Nutritional - Data Scientist - PBI - Final Project 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16jsbtcpw5jAZV_eihqouU8FIc9iCk1ku

# Total Sales Prediction Using ARIMA

Author: Jaelani (Jay)

**Content:**
1.   Introduction
2.   Importing Libraries
3.   Dataset Overview
4.   Data Cleaning
5.   Model Machine Learning

# 1. Introduction

**Dataset Informastion**
*   Dataset ini terdiri dari 4 csv file yaitu customer, store, product dan transaction.
*   Merupakan dummy data untuk studi kasus FMCG dalam kurun waktu 1 tahun yang diambil melalui program membership.

**Attribute Information**
*   Customer
 - `CustomerID`: No Unik Customer
 - `Age`: Usia Customer
 - `Gender`: 0 Wanita, 1 Pria
 - `Marital Status`: Married, Single (Blm menikah/Pernah menikah)
 - `Income` : Pendapatan per bulan dalam jutaan rupiah

*   Store
 - `StoreID`: Kode Unik Store
 - `StoreName`: Nama Toko
 - `GroupStore`: Nama group
 - `Type`: Modern Trade, General Trade
 - `Latitude`: Kode Latitude
 - `Longitude`: Kode Longitude

*   Product
 - `ProductID`: Kode Unik Product
 - `Product Name`: Nama Product
 - `Price`: Harga dlm rupiah

*   Transaction
 - `TransactionID`: Kode Unik Transaksi
 - `Date`: Tanggal transaksi
 - `Qty`: Jumlah item yang dibeli
 - `Total Amount`: Price x Qty

**Company Goals**
*   Kamu adalah seorang Data Scientist di Kalbe Nutritionals dan sedang mendapatkan project baru dari tim inventory.
*   Dari tim inventory, kamu diminta untuk dapat membantu memprediksi jumlah penjualan (quantity) dari total keseluruhan product Kalbe

**Objectives**
*   Untuk mengetahui perkiraan quantity product yang terjual sehingga tim inventory dapat membuat stock persediaan harian yang cukup.
*   Prediksi yang dilakukan harus harian

# 2. Importing Libraries
"""

# Installing Library ARIMA
! pip install pmdarima

# Basic
import pandas as pd
import numpy as np

# Data Viz
import matplotlib.pyplot as plt
import seaborn as sns

# Melihat Pola Data (Trend, Seasonality, Residual)
from statsmodels.tsa.seasonal import seasonal_decompose

# Stationary Test
from statsmodels.tsa.stattools import adfuller

# Verifikasi using Autocorrelation Plot
from statsmodels.graphics.tsaplots import plot_acf
# Partial Autocorrelation Plot
from statsmodels.graphics.tsaplots import plot_pacf

# ARIMA Model
from pmdarima.arima import auto_arima
from statsmodels.tsa.arima.model import ARIMA
import pmdarima as pm
from pandas.plotting import autocorrelation_plot

# Model Evaluasi
from sklearn.metrics import mean_absolute_error, mean_squared_error

import warnings
warnings.filterwarnings('ignore')

"""# 3. Dataset Overview

## 3.1. Reading Dataset
"""

customer = pd.read_csv('/content/drive/MyDrive/Datasets/Dataset Kalbe Nutritional - Data Scientist - PBI - Final Project/Case Study - Customer.csv', delimiter=';')
product = pd.read_csv('/content/drive/MyDrive/Datasets/Dataset Kalbe Nutritional - Data Scientist - PBI - Final Project/Case Study - Product.csv', delimiter=';')
store = pd.read_csv('/content/drive/MyDrive/Datasets/Dataset Kalbe Nutritional - Data Scientist - PBI - Final Project/Case Study - Store.csv', delimiter=';')
transaction = pd.read_csv('/content/drive/MyDrive/Datasets/Dataset Kalbe Nutritional - Data Scientist - PBI - Final Project/Case Study - Transaction.csv', delimiter=';')

customer.head()

product.head()

store.head()

transaction.head()

"""## 3.2. Data Shape


"""

customer.shape, product.shape, store.shape, transaction.shape

"""# 4. Data Cleaning

## 4.1. Data Merge
"""

df = pd.merge(transaction,customer,on='CustomerID', how='inner')
df = pd.merge(df,product,on='ProductID',how='inner')
df = pd.merge(df,store,on='StoreID', how='inner')
df.head()

"""## 4.2. Data Shape"""

df.shape

"""## 4.3. Data Type Checking"""

df.dtypes

"""### 4.3.1. Change Date Datatype"""

df['Date'] = pd.to_datetime(df['Date'])

df.dtypes

"""## 4.4 Data Column Change"""

# Merubah tanda pada kolom income
df['Income'] = df['Income'].map(lambda x: float(x.replace(',','.')))

df

# Merubah tanda pada kolom income
df['Latitude'] = df['Latitude'].map(lambda x: float(x.replace(',','.')))
df['Longitude'] = df['Longitude'].map(lambda x: float(x.replace(',','.')))

"""## 4.5. Data Duplicates Checking


"""

df.duplicated().sum()

"""## 4.6. Missing Value Checking"""

df.isna().sum()

"""### 4.6.1. Checking Variable in Column `Marital Status`"""

df['Marital Status'].unique()

"""### 4.6.2. Data Imputation with Mode"""

df['Marital Status'] = df['Marital Status'].fillna(df['Marital Status'].mode()[0])

df['Marital Status'].unique()

df.isna().sum()

# Export the cleaned data into a csv format
df.to_csv('/content/drive/MyDrive/Datasets/Dataset Kalbe Nutritional - Data Scientist - PBI - Final Project/Merged_Data.csv', index=False)

# Export the csv to excel
Merged_Data_Excel = pd.ExcelWriter('/content/drive/MyDrive/Datasets/Dataset Kalbe Nutritional - Data Scientist - PBI - Final Project/Merged_Data.xlsx')
df.to_excel(Merged_Data_Excel, index=False)

Merged_Data_Excel.save()

"""# 5. Model Machine Learning (Time Series Analysis and Forecasting)

## 5.1. Data Preparation
"""

data_tsa = df.groupby(['Date']).agg({
    'Qty' : 'sum'
}).reset_index()

data_tsa.info()

data_tsa

"""## 5.2. Melihat Pola - Pola Data"""

decomposed = seasonal_decompose(data_tsa.set_index('Date'))

plt.figure(figsize=(10, 10))

plt.subplot(311)
decomposed.trend.plot(ax=plt.gca(), color='#59A14F')
plt.title('Trend')
plt.subplot(312)
decomposed.seasonal.plot(ax=plt.gca(), color='#59A14F')
plt.title('Seasonality')
plt.subplot(313)
decomposed.resid.plot(ax=plt.gca(), color='#59A14F')
plt.title('Residual')

plt.tight_layout()

"""## 5.3. Stationarity Test"""

result = adfuller(data_tsa['Qty'])
print('ADF Statistic: %f' % result[0])
print('p-value: %f' % result[1])
print('Critical Values:')
for key, value in result[4].items():
    print('\t%s: %.3f' % (key, value))

"""P-Value < 0,05 sehingga data stationery dapat digunakan dalam analisis time series dengan ARIMA."""

plt.figure(figsize=(20,5))
sns.lineplot(data=data_tsa, x=data_tsa['Date'], y=data_tsa['Qty'], color='#59A14F')

"""## 5.4. Finding The Value of The p, d, q Parameter

### 5.4.1. Finding the value of the d parameter
"""

plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})

fig, (ax1, ax2, ax3) = plt.subplots(3)

ax1.plot(data_tsa.Qty, color='royalblue'); ax1.set_title('Original Series'); ax1.axes.xaxis.set_visible(False)

ax2.plot(data_tsa.Qty.diff(), color='royalblue'); ax2.set_title('1st Order Differencing'); ax2.axes.xaxis.set_visible(False)

ax3.plot(data_tsa.Qty.diff().diff(), color='royalblue'); ax3.set_title('2nd Order Differencing')

plt.show()

"""### 5.4.2. Melakukan Verifikasi d Parameter dengan Autocorelation Plot"""

fig, (ax1, ax2, ax3) = plt.subplots(3)
plot_acf(data_tsa.Qty, color='royalblue', ax=ax1); ax1.axes.xaxis.set_visible(False)
plot_acf(data_tsa.Qty.diff().dropna(), color='royalblue', ax=ax2); ax2.axes.xaxis.set_visible(False)
plot_acf(data_tsa.Qty.diff().diff().dropna(), color='royalblue', ax=ax3);

"""### 5.4.3. Finding the value of the p parameter"""

plot_pacf(data_tsa.Qty.diff().dropna(), color='royalblue');

"""### 5.4.4. Finding the value of the q parameter"""

plot_acf(data_tsa.Qty.diff().dropna(), color='royalblue');

"""## 5.5. Building ARIMA Model"""

# train-test split
cut_off = round(data_tsa.shape[0]*0.8)
df_train = data_tsa[:cut_off]
df_test = data_tsa[cut_off:].reset_index(drop=True)
df_train.shape, df_test.shape

# Pada Time series Analysis, data test harus melanjutkan data train

df_train

df_test

# train-test split line

plt.figure(figsize=(20,5))
sns.lineplot(data=df_train, x=df_train['Date'], y=df_train['Qty'], color='#F28E2B')
sns.lineplot(data=df_test, x=df_test['Date'], y=df_test['Qty'], color='#59A14F')

#autocorrelation plot

autocorrelation_plot(data_tsa['Qty'], color='#59A14F')

# defining evaluation model

def rmse(y_actual, y_pred):
    """
    function to calculate RMSE
    """

    print(f'RMSE value {mean_squared_error(y_actual, y_pred)**0.5}')

def eval(y_actual, y_pred):
    """
    function to eval machine learning modelling
    """

    rmse(y_actual, y_pred)
    print(f'MAE value {mean_absolute_error(y_actual, y_pred)}')

y = df_train['Qty']

df_train = df_train.set_index('Date')
df_test = df_test.set_index('Date')

# hasil forcasting all product with results of evaluation model

ARIMAmodel = ARIMA(y, order=(50, 0, 2))
ARIMAmodel = ARIMAmodel.fit()

y_pred = ARIMAmodel.get_forecast(len(df_test))

y_pred_df = y_pred.conf_int()
y_pred_df['predictions'] = ARIMAmodel.predict(start=y_pred_df.index[0], end=y_pred_df.index[-1])
y_pred_df.index = df_test.index
y_pred_out = y_pred_df['predictions']
eval(df_test['Qty'], y_pred_out)

plt.figure(figsize=(20, 5))
plt.plot(df_train['Qty'], color='#F28E2B')
plt.plot(df_test['Qty'], color='#59A14F')
plt.plot(y_pred_out, color='#555555', label='ARIMA Predictions')
plt.legend()

# auto arima best model and prediction results

model = auto_arima(df_train, trace=True, error_action='ignore', suppress_warnings=True)
model.fit(df_train)
forecast = model.predict(n_periods=len(df_test))
forecast = pd.DataFrame(forecast, index=df_test.index, columns=['Predictions'])
print(forecast)

#Plot forecasting

plt.figure(figsize=(12,5))
plt.plot(df_train, label='Training Data')
plt.plot(df_test, color='orange', label='Test Data')
plt.plot(forecast,color='red', label= 'Quantity Forecast')
plt.title('Quantity Sold Forecasting')
plt.legend()
plt.show()

forecast.mean()

#Forecasting the quantity of each product for the next month
product_name = df['Product Name'].unique()

dfprod = pd.DataFrame({'Date':pd.date_range(start='2023-01-01',end='2023-01-31')})
dfprod = dfprod.set_index('Date')
for i in product_name:
    df1 = df[['Date','Product Name','Qty']]
    df1 = df1[df1['Product Name']==i]
    df1 = df1.groupby('Date')[['Qty']].sum()
    df1 = df1.reset_index()
    df_prod = pd.DataFrame({'Date':pd.date_range(start='2022-01-01',end='2022-12-31')})
    df_prod = df_prod.merge(df1, how='left', on='Date')
    df_prod = df_prod.fillna(0)
    df_prod = df_prod.set_index('Date')

    model1 = ARIMA(df_prod, order=(1,0,1))
    model1_fit = model1.fit()
    forecast1 = model1_fit.forecast(steps=31)
    dfprod[i] = forecast1.values

dfprod.head()

#Forecasting Plot
plt.figure(figsize=(20,5))
plt.plot(dfprod)
plt.legend(dfprod.columns,loc='center left', bbox_to_anchor=(1, 0.5))
plt.title('Quantity of Each Product Sold Forecast')
plt.show()

#Plot forecasting
plt.figure(figsize=(20,10))
plt.plot(df_prod)
plt.plot(dfprod, label= 'Quantity of Each Product Forecast')
plt.title('Quantity of Each Product Sold Forecast')
plt.legend(dfprod.columns, loc='center left', bbox_to_anchor=(1,0.5))
plt.show()

#Quantity of Each Product Sold forecast
round(dfprod.describe().T['mean'],0)